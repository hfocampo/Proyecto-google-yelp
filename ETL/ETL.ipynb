{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bKcnpa5wtgpM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estadios con la dirección polar latitud y longitud\n",
        "\"\"\"\n",
        "Ciudad\t                Estado\t                Estadio\t                Capacidad\tlatitud\t    longitud\n",
        "Atlanta\t                Georgia\t                Mercedes-Benz Stadium   71.000 \t    33.755489\t-84.401993\n",
        "Boston\t                Massachuts\t            Gillette Stadium\t    68.756 \t    42.0922 \t-71.2642\n",
        "Dallas\t                Texas\t                AT&T Stadium\t        80.000 \t    32.747841\t-97.093628\n",
        "Houston\t                Texas\t                NRG Stadium\t            72.220 \t    29.684860\t-95.411667\n",
        "Kansas City\t            Misuri\t                Arrowhead Stadium\t    76.416 \t    39.048786\t-94.484566\n",
        "Los Angeles\t            California\t            SoFi Stadium\t        70.000 \t    33.953587\t-118.339630\n",
        "Miami\t                Florida                 Hard Rock Stadium\t    65.326 \t    25.957960\t-80.239311\n",
        "New York/New Jersey     New York/New Jersey     MetLife Stadium\t        82.500 \t    40.813778\t-74.074310\n",
        "Philadelfia\t            Pensilvania\t            Lincoln Financial Field 67.594 \t    39.900898\t-75.168098\n",
        "San Francisco\t        California\t            Levi's Stadium\t        68.500 \t    37.4036\t    -121.9702\n",
        "Seatle\t                Washinton\t            Lumen Field     \t    72.000 \t    47.595097\t-122.332245\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19aS-kDMtyIJ"
      },
      "source": [
        "Creamos funcion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "heTJOqErt1Lf"
      },
      "outputs": [],
      "source": [
        "def encontrar_sitios_cercanos(df_cercanos, df_metadata_sitios, punto1, distancia1):\n",
        "    # Iterar sobre los registros del DataFrame original\n",
        "    for index, row in df_metadata_sitios.iterrows():\n",
        "        latitud = row['latitude']\n",
        "        longitud = row['longitude']\n",
        "        punto2 = (latitud, longitud)\n",
        "        # Calcular la distancia entre el punto1 y el punto2\n",
        "        distancia = euclidean(punto1, punto2) * 100\n",
        "        # Verificar si la distancia es menor o igual a 50 km\n",
        "        if distancia <= distancia1:\n",
        "            # Almacenar el registro completo en el nuevo DataFrame\n",
        "            df_cercanos.loc[len(df_cercanos)] = row\n",
        "    return df_cercanos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll7ZAZj_t5Sn"
      },
      "source": [
        "Leer dataset meda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RzIvz8Kpt9Ax"
      },
      "outputs": [],
      "source": [
        "metada_sitios = pd.read_parquet('../Dataset Final Google/Metadata Sitios/metadata_sitios.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj96_o2d7TM_"
      },
      "source": [
        "Borramos columna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iSzZuxQaxZOk"
      },
      "outputs": [],
      "source": [
        "metada_sitios.drop(columns= ['url','relative_results', 'MISC', 'description', 'price','hours'], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPFxz_jPzdAL"
      },
      "source": [
        "Desanidamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M-UJzwzXzpM7"
      },
      "outputs": [],
      "source": [
        "metadata_sitios_final = metada_sitios.explode(column= \"category\") # creamos un dataframe donde duplica,os las filas de acuerdo a la cantidad de subcampos que hay en la columna review.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0t_Ymjg7fhA"
      },
      "source": [
        "Borramos duplicados por gmap_id y reseteamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nmg_DG-o3Lr1"
      },
      "outputs": [],
      "source": [
        "metadata_sitios_final.drop_duplicates(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1v7x3HlJ3bYS"
      },
      "outputs": [],
      "source": [
        "metadata_sitios_final.reset_index(inplace=True, drop=True) # Reseteamos los indices del dataframe desanidado para poder concatenar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-sxx6k_7-fe"
      },
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo9oj58W3znV"
      },
      "outputs": [],
      "source": [
        "metadata_sitios_final.to_parquet('../Estadios_reviews/metadata_sitios_final.parquet', compression= 'Gzip', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Arrowhead Stadium - MISSOURI y KANSAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leemos datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cargar el conjunto de datos de negocios filtrados\n",
        "missouri=pd.read_parquet('../Dataset Final Google/Reviews Estados/Missouri.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cargar el conjunto de datos de negocios filtrados\n",
        "kansas=pd.read_parquet('../Dataset Final Google/Reviews Estados/Kansas.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Combinamos ambos df\n",
        "missouri_kansas = pd.concat([missouri, kansas], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformamos y borramos columnas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "missouri_kansas.drop(columns=['pics' ,'resp','name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# missouri_kansas['time'] = pd.to_datetime(missouri_kansas['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "missouri_kansas['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missouri_kansas.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missouri_kansas.to_parquet('../Estadios_reviews/missouri_kansas.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "punto_missouri_kansas = (39.048786, -94.484566) # Establecemos el estadio: Arrowhead Stadium - Kansas City - Estado de Misuri\n",
        "\n",
        "distancia = 50 # Distancia 50 kilometros cerca del estadio\n",
        "\n",
        "# Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_missouri_kansas = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_missouri_kansas = encontrar_sitios_cercanos(df_cercanos_missouri_kansas, metadata_sitios_final, punto_missouri_kansas, distancia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado__missouri_kansas = pd.merge(missouri_kansas, df_cercanos_missouri_kansas, on='gmap_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado__missouri_kansas.to_parquet('../Datasets_final/Arrowhead_Stadium.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcN2IhbZG2oo"
      },
      "source": [
        "## MetLife Stadium- NEW JERSEY y NEW YORK:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leemos los df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xruM6alCHzmH"
      },
      "outputs": [],
      "source": [
        "New_Jersey = pd.read_parquet('../Dataset Final Google/Reviews Estados/New_Jersey.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "eM43kVAsH021",
        "outputId": "75034eee-b531-45f8-f96f-4b4ef932a1c7"
      },
      "outputs": [],
      "source": [
        "New_York = pd.read_parquet('../Dataset Final Google/Reviews Estados/New_York.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_jersey_new_york = pd.concat([New_Jersey, New_York], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "new_jersey_new_york.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new_jersey_new_york['time'] = pd.to_datetime(new_jersey_new_york['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "new_jersey_new_york['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_jersey_new_york.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_jersey_new_york.to_parquet('../Estadios_reviews/new_jersey_new_york.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutamos la funcion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "punto1 = (40.813778, -74.074310) #MetLife Stadium - New York/New Jersey - Estados de New York/New Jersey\n",
        "\n",
        "distancia = 50 # Distancia 30 kilometros cerca del estadio \n",
        "\n",
        "# Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_new_jersey_new_york = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_new_jersey_new_york = encontrar_sitios_cercanos(df_cercanos_new_jersey_new_york, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unimos con los datasets estados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado_new_jersey_new_york = pd.merge(new_jersey_new_york, df_cercanos_new_jersey_new_york, on='gmap_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_new_jersey_new_york.to_parquet('../Datasets_final/MetLife_Stadium.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lincoln Financial Field - PENSILVANIA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leemos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "pensilvania = pd.read_parquet('../Dataset Final Google/Reviews Estados/Pensilvania.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "pensilvania.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pensilvania['time'] = pd.to_datetime(pensilvania['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_6164\\3116476257.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  pensilvania['text'].fillna('Neutral', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "pensilvania['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "pensilvania.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pensilvania.to_parquet('../Estadios_reviews/pensilvania.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutamos funcion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "punto1 = (39.900898,-75.168098) #Lincoln Financial Field - Philadelfia - Estado de Pensilvania\n",
        "\n",
        "distancia = 50 # Distancia 30 kilometros cerca del estadio \n",
        "\n",
        "# Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_pensilvania = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_pensilvania = encontrar_sitios_cercanos(df_cercanos_pensilvania, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unimos: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset de reviews del estado respectivo\n",
        "df_filtrado_pensilvania = pd.merge(pensilvania, df_cercanos_pensilvania, on='gmap_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_pensilvania.to_parquet('../Datasets_final/Lincoln_Financial_Field.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gillete Stadium - MASSACHUSETTS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leemos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "massachusetts = pd.read_parquet('../Dataset Final Google/Reviews Estados/massachusetts.parquet') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "massachusetts.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# massachusetts['time'] = pd.to_datetime(massachusetts['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_6164\\3944610266.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  massachusetts['text'].fillna('Neutral', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "massachusetts['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "massachusetts.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "massachusetts.to_parquet('../Estadios_reviews/massachusetts.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usamos la funcion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "punto1 = (42.0922, -71.2642) # Gillete Stadium - Boston - Estado de Massachutts\n",
        "\n",
        "distancia = 50 # Distancia 30 kilometros cerca del estadio \n",
        "\n",
        "# Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_massachusetts = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_massachusetts = encontrar_sitios_cercanos(df_cercanos_massachusetts, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unimos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset de reviews del estado respectivo\n",
        "df_cercanos_massachusetts = pd.merge(massachusetts, df_cercanos_massachusetts, on='gmap_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cercanos_massachusetts.to_parquet('../Datasets_final/Gillete_Stadium.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SoFi Stadium y LEVI´S STADIUM - CALIFORNIA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leer datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cargar el conjunto de datos de negocios filtrados \n",
        "california = pd.read_parquet('../Dataset Final Google/Reviews Estados/California.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformacion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "california.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# california['time'] = pd.to_datetime(california['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_6164\\3185630916.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  california['text'].fillna('Neutral', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "california['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "california.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Guardamos la data limpia\n",
        "california.to_parquet('../Estadios_reviews/california.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aplicamos funcion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ubicacion del estadio SOFI STADIUM\n",
        "punto1 = (33.953587, -118.339630) #SoFi Stadium - Los Angeles - Estado de California\n",
        "#Distancia a la redonda del estadio donde se quiere ubicar los puntos, dada en kilómetros\n",
        "distancia = 50\n",
        "#Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_california = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_california = encontrar_sitios_cercanos(df_cercanos_california, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unimos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado_california = pd.merge(california, df_cercanos_california, on='gmap_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_california.to_parquet('../Datasets_final/SoFi_Stadium.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aplicacion Funcion 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ubicacion del estadio LEVI´S STADIUM\n",
        "punto1 = (37.4036, -121.9702) #Levi's Stadium - San Francisco - Estado de California\n",
        "#Distancia a la redonda del estadio donde se quiere ubicar los puntos, dada en kilómetros\n",
        "distancia = 50\n",
        "#Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_california2 = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_california2 = encontrar_sitios_cercanos(df_cercanos_california2, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado_california2 = pd.merge(california, df_cercanos_california2, on='gmap_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_california2.to_parquet('../Datasets_final/LEVI´S_STADIUM.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HARD ROCK STADIUM - FLORIDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leer df:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cargar el conjunto de datos de negocios filtrados \n",
        "florida = pd.read_parquet('../Dataset Final Google/Reviews Estados/Florida.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "florida.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# florida['time'] = pd.to_datetime (florida['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_6164\\4070066519.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  florida['text'].fillna('Neutral', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "florida['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "florida.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Guardamos la data limpia\n",
        "florida.to_parquet('../Estadios_reviews/florida.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aplicacion funcion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ubicacion del estadio HARD ROCK STADIUM\n",
        "punto1 = (25.957960, -80.239311) #Hard Rock Stadium - Miami - Estado de La Florida\n",
        "#Distancia a la redonda del estadio donde se quiere ubicar los puntos, dada en kilómetros\n",
        "distancia = 50\n",
        "#Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_florida = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_florida = encontrar_sitios_cercanos(df_cercanos_florida, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unimos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado_florida = pd.merge(florida, df_cercanos_florida, on='gmap_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_florida.to_parquet('../Datasets_final/HARD_ROCK_STADIUM.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mercedes-Benz - GEORGIA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cargar el conjunto de datos de negocios filtrados \n",
        "georgia = pd.read_parquet('../Dataset Final Google/Reviews Estados/georgia.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformacion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "georgia.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# georgia['time'] = pd.to_datetime(georgia['time'],unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_6164\\155885781.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  georgia['text'].fillna('Neutral', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "georgia['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "georgia.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Guardamos la data limpia\n",
        "georgia.to_parquet('../Estadios_reviews/georgia.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ubicacion del estadio\n",
        "punto1 = (33.755489, -84.401993) #Mercedes-Benz Stadium - Atlanta - Estado de Georgia\n",
        "#Distancia a la redonda del estadio donde se quiere ubicar los puntos, dada en kilómetros\n",
        "distancia = 50\n",
        "#Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_georgia = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_georgia = encontrar_sitios_cercanos(df_cercanos_georgia, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unimos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset de reviews del estado\n",
        "df_filtrado_georgia = pd.merge(georgia, df_cercanos_georgia, on='gmap_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_georgia.to_parquet('../Datasets_final/Mercedes_Benz.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AT&T Stadium y NRG Stadum - TEXAS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cargar el conjunto de datos de negocios filtrados \n",
        "texas = pd.read_parquet('../Dataset Final Google/Reviews Estados/Texas.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "texas.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# texas['time'] = pd.to_datetime(texas['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_6164\\615764583.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  texas['text'].fillna('Neutral', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "texas['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "texas.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Guardamos la data limpia\n",
        "texas.to_parquet('../Estadios_reviews/texas.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aplicamos Funcion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ubicacion del estadio\n",
        "punto1 = (32.747841, -97.093628) #AT&T Stadium - Dallas - Estado de Texas\n",
        "#Distancia a la redonda del estadio donde se quiere ubicar los puntos, dada en kilómetros\n",
        "distancia = 50\n",
        "#Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_texas = pd.DataFrame(columns= metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_texas = encontrar_sitios_cercanos(df_cercanos_texas, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado_texas = pd.merge(texas, df_cercanos_texas, on='gmap_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_texas.to_parquet('../Datasets_final/AT&T_Stadium.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aplicar funcion 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ubicacion del estadio\n",
        "punto1 = (29.684860, -95.411667) #NRG Stadum - Houston - Estado de Texas\n",
        "#Distancia a la redonda del estadio donde se quiere ubicar los puntos, dada en kilómetros\n",
        "distancia = 50\n",
        "#Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_texas2 = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_texas2 = encontrar_sitios_cercanos(df_cercanos_texas2, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado_texas2 = pd.merge(texas, df_cercanos_texas2, on='gmap_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_texas2.to_parquet('../Datasets_final/NRG_Stadum.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lumen Field - WASHINGTON:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cargar el conjunto de datos de negocios filtrados \n",
        "washington = pd.read_parquet('../Dataset Final Google/Reviews Estados/Washington.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Eliminamos las columnas que no necesaritaremos y la que contengan muchos valores nulos\n",
        "washington.drop(columns=['pics' ,'resp', 'name'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# washington['time'] = pd.to_datetime(washington['time'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_6164\\2831210142.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  washington['text'].fillna('Neutral', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "washington['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "washington.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Guardamos la data limpia\n",
        "washington.to_parquet('../Estadios_reviews/washington.parquet',compression='gzip', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aplicamos funciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ubicacion del estadio\n",
        "punto1 = (47.595097, -122.332245) #Lumen Field latitud - Seatle - Estado de Washington\n",
        "#Distancia a la redonda del estadio donde se quiere ubicar los puntos, dada en kilómetros\n",
        "distancia = 50\n",
        "#Crea un DataFrame vacío para almacenar los registros que cumplen con la condición\n",
        "df_cercanos_washington = pd.DataFrame(columns=metadata_sitios_final.columns)  # Asumiendo que df es el DataFrame original\n",
        "#Llama la función para encontrar todos los puntos cercanos a la distancia seleccionada\n",
        "df_cercanos_washington = encontrar_sitios_cercanos(df_cercanos_washington, metadata_sitios_final, punto1, distancia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtra el resultado de la metadata con el dataset del estado\n",
        "df_filtrado_washington = pd.merge(washington, df_cercanos_washington, on='gmap_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtrado_washington.to_parquet('../Datasets_final/Lumen_Field.parquet', compression='gzip',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combinamos los dataframes finales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "Arrowhead_Stadium = pd.read_parquet('../Datasets_final/Arrowhead_Stadium.parquet')\n",
        "ATyT_Stadium = pd.read_parquet('../Datasets_final/AT&T_Stadium.parquet')\n",
        "Gillete_Stadium = pd.read_parquet('../Datasets_final/Gillete_Stadium.parquet')\n",
        "HARD_ROCK_STADIUM = pd.read_parquet('../Datasets_final/HARD_ROCK_STADIUM.parquet')\n",
        "LEVI_STADIUM = pd.read_parquet('../Datasets_final/LEVI´S_STADIUM.parquet')\n",
        "Lincoln_Financial_Field = pd.read_parquet('../Datasets_final/Lincoln_Financial_Field.parquet')\n",
        "Lumen_Field = pd.read_parquet('../Datasets_final/Lumen_Field.parquet')\n",
        "Mercedes_Benz = pd.read_parquet('../Datasets_final/Mercedes_Benz.parquet')\n",
        "MetLife_Stadium = pd.read_parquet('../Datasets_final/MetLife_Stadium.parquet')\n",
        "NRG_Stadum = pd.read_parquet('../Datasets_final/NRG_Stadum.parquet')\n",
        "SoFi_Stadium = pd.read_parquet('../Datasets_final/SoFi_Stadium.parquet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estadios con la dirección polar latitud y longitud\n",
        "\"\"\"\n",
        "Ciudad\t                Estado\t                Estadio\t                Capacidad\tlatitud\t    longitud\n",
        "Atlanta\t                Georgia\t                Mercedes-Benz Stadium   71.000 \t    33.755489\t-84.401993\n",
        "Boston\t                Massachuts\t            Gillette Stadium\t    68.756 \t    42.0922 \t-71.2642\n",
        "Dallas\t                Texas\t                AT&T Stadium\t        80.000 \t    32.747841\t-97.093628\n",
        "Houston\t                Texas\t                NRG Stadum\t            72.220 \t    29.684860\t-95.411667\n",
        "Kansas City\t            Misuri\t                Arrowhead Stadium\t    76.416 \t    39.048786\t-94.484566\n",
        "Los Angeles\t            California\t            SoFi Stadium\t        70.000 \t    33.953587\t-118.339630\n",
        "Miami\t                Florida                 Hard Rock Stadium\t    65.326 \t    25.957960\t-80.239311\n",
        "New York/New Jersey     New York/New Jersey     MetLife Stadium\t        82.500 \t    40.813778\t-74.074310\n",
        "Philadelfia\t            Pensilvania\t            Lincoln Financial Field 67.594 \t    39.900898\t-75.168098\n",
        "San Francisco\t        California\t            Levi's Stadium\t        68.500 \t    37.4036\t    -121.9702\n",
        "Seatle\t                Washinton\t            Lumen Field     \t    72.000 \t    47.595097\t-122.332245\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agregar columnas nuevas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "Arrowhead_Stadium = pd.read_parquet('../Datasets_final/Arrowhead_Stadium.parquet')\n",
        "Arrowhead_Stadium['Estadio cercano'] = 'Arrowhead Stadium'\n",
        "Arrowhead_Stadium['Ciudad'] = 'Kansas City'\n",
        "Arrowhead_Stadium['Estado'] = 'Misuri'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "ATyT_Stadium = pd.read_parquet('../Datasets_final/AT&T_Stadium.parquet')\n",
        "ATyT_Stadium['Estadio cercano'] = 'AT&T Stadium'\n",
        "ATyT_Stadium['Ciudad'] = 'Dallas'\n",
        "ATyT_Stadium['Estado'] = 'Texas'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "Gillete_Stadium = pd.read_parquet('../Datasets_final/Gillete_Stadium.parquet')\n",
        "Gillete_Stadium['Estadio cercano'] = 'Gillete Stadium'\n",
        "Gillete_Stadium['Ciudad'] = 'Boston'\n",
        "Gillete_Stadium['Estado'] = 'Massachusetts'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "HARD_ROCK_STADIUM = pd.read_parquet('../Datasets_final/HARD_ROCK_STADIUM.parquet')\n",
        "HARD_ROCK_STADIUM['Estadio cercano'] = 'Hard Rock Stadium'\n",
        "HARD_ROCK_STADIUM['Ciudad'] = 'Miami'\n",
        "HARD_ROCK_STADIUM['Estado'] = 'Florida'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "LEVI_STADIUM = pd.read_parquet('../Datasets_final/LEVI´S_STADIUM.parquet')\n",
        "LEVI_STADIUM['Estadio cercano'] = 'Levi´s Stadium'\n",
        "LEVI_STADIUM['Ciudad'] = 'San Francisco'\n",
        "LEVI_STADIUM['Estado'] = 'California'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lincoln_Financial_Field = pd.read_parquet('../Datasets_final/Lincoln_Financial_Field.parquet')\n",
        "Lincoln_Financial_Field['Estadio cercano'] = 'Lincoln Financial Field'\n",
        "Lincoln_Financial_Field['Ciudad'] = 'Philadelfia'\n",
        "Lincoln_Financial_Field['Estado'] = 'Pennsylvania'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lumen_Field = pd.read_parquet('../Datasets_final/Lumen_Field.parquet')\n",
        "Lumen_Field['Estadio cercano'] = 'Lumen Field'\n",
        "Lumen_Field['Ciudad'] = 'Sattle'\n",
        "Lumen_Field['Estado'] = 'Washinton'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "Mercedes_Benz = pd.read_parquet('../Datasets_final/Mercedes_Benz.parquet')\n",
        "Mercedes_Benz['Estadio cercano'] = 'Mercedes-Benz Stadium'\n",
        "Mercedes_Benz['Ciudad'] = 'Atlanta'\n",
        "Mercedes_Benz['Estado'] = 'Georgia'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "MetLife_Stadium = pd.read_parquet('../Datasets_final/MetLife_Stadium.parquet')\n",
        "MetLife_Stadium['Estadio cercano'] = 'MetLife Stadium'\n",
        "MetLife_Stadium['Ciudad'] = 'Bergen'\n",
        "MetLife_Stadium['Estado'] = 'Nueva York/Nueva Jersey'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "NRG_Stadum = pd.read_parquet('../Datasets_final/NRG_Stadum.parquet')\n",
        "NRG_Stadum['Estadio cercano'] = 'NRG Stadium'\n",
        "NRG_Stadum['Ciudad'] = 'Houston'\n",
        "NRG_Stadum['Estado'] = 'Texas'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "SoFi_Stadium = pd.read_parquet('../Datasets_final/SoFi_Stadium.parquet')\n",
        "SoFi_Stadium['Estadio cercano'] = 'SoFi Stadium'\n",
        "SoFi_Stadium['Ciudad'] = 'Los Angeles'\n",
        "SoFi_Stadium['Estado'] = 'California'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unimos y borramos duplicados y guardamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "lista_datasets_estadios = [Arrowhead_Stadium,ATyT_Stadium,Gillete_Stadium,HARD_ROCK_STADIUM,LEVI_STADIUM,Lincoln_Financial_Field,Lumen_Field,Mercedes_Benz,MetLife_Stadium,NRG_Stadum,SoFi_Stadium]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_ultimo_final = pd.concat(lista_datasets_estadios, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataset_ultimo_final' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataset_ultimo_final\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataset_ultimo_final' is not defined"
          ]
        }
      ],
      "source": [
        "dataset_ultimo_final.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_ultimo_final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Modificamos los reviews faltante por Neutral\n",
        "dataset_ultimo_final['text'].fillna('Neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_ultimo_final.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_ultimo_final.to_parquet('./dataset_ultimo_final.parquet', compression='gzip', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
